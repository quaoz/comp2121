{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1473ae58-d12c-41ed-af33-db8fd6245214",
   "metadata": {},
   "source": [
    "# Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c3e64-dc27-4af7-8c97-abb879ca0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import torch\n",
    "from optuna.exceptions import TrialPruned\n",
    "from optuna.pruners import MedianPruner\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from ensemble_model import EnsembleModel\n",
    "from extract_features import (\n",
    "    extract_linguistic_features,\n",
    "    extract_sbert_features,\n",
    "    extract_semantic_features,\n",
    ")\n",
    "from prepare_data import extract_claim_evidence_pairs, load_jsonl\n",
    "from tune_model import ScifactDataset, train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef4bb8-defb-4391-87de-b4fcc538c146",
   "metadata": {},
   "source": [
    "# Util\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d0c99-5a87-455a-85ea-2fa9a29cbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "device_str = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = torch.device(device_str)\n",
    "\n",
    "evidence_decode = {0: \"NOT EVIDENCE\", 1: \"EVIDENCE\"}\n",
    "evidence_encode = {\"NOT EVIDENCE\": 0, \"EVIDENCE\": 1}\n",
    "\n",
    "label_decode = {0: \"SUPPORT\", 1: \"CONTRADICT\", 2: \"NO_RELATION\"}\n",
    "label_encode = {\"SUPPORT\": 0, \"CONTRADICT\": 1, \"NO_RELATION\": 2}\n",
    "\n",
    "drop_features = [\"claim_id\", \"doc_id\", \"label\", \"is_evidence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5fa7b-a244-4732-93dc-c053a130ae25",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1bd3a8-59f8-4c67-adfd-f5730b42a5f3",
   "metadata": {},
   "source": [
    "Load the scifact corups and training and development fact sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0856d-d1ea-43bc-b531-ab3e2de476fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCIFACT_DIR = os.getenv(\"SCIFACT_DATA\")\n",
    "CORPUS_PATH = os.path.join(SCIFACT_DIR, \"corpus.jsonl\")\n",
    "CLAIMS_TRAIN_PATH = os.path.join(SCIFACT_DIR, \"claims_train.jsonl\")\n",
    "CLAIMS_DEV_PATH = os.path.join(SCIFACT_DIR, \"claims_dev.jsonl\")\n",
    "\n",
    "corpus = load_jsonl(CORPUS_PATH)\n",
    "claims_train = load_jsonl(CLAIMS_TRAIN_PATH)\n",
    "claims_dev = load_jsonl(CLAIMS_DEV_PATH)\n",
    "\n",
    "corpus_dict = {doc[\"doc_id\"]: doc for doc in corpus}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c5789-51f6-4a1f-b32c-6ac779e10766",
   "metadata": {},
   "source": [
    "Extract claim-evidence pairs from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193189d-f329-49d5-bd74-850a68dfa314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = extract_claim_evidence_pairs(claims_train, corpus_dict)\n",
    "dev_df = extract_claim_evidence_pairs(claims_dev, corpus_dict)\n",
    "\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Development set: {len(dev_df)} samples\")\n",
    "print(\"\\nLabel distribution in training set:\")\n",
    "display(train_df[\"label\"].value_counts().to_frame())\n",
    "print(\"\\nEvidence vs Non-evidence in training set:\")\n",
    "display(train_df[\"is_evidence\"].map(evidence_decode).value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a059bb-2d78-4f43-8bff-24c3270a5a2f",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd40089-375c-440c-bf77-90b4b2100469",
   "metadata": {},
   "source": [
    "Extract features from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910bab7-b99e-4294-a40e-3c0c42d3b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\", model_kwargs={\"torch_dtype\": \"float16\"}, device=device_str\n",
    ")\n",
    "spacy_model = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def extract_features_parallel(df, spacy_model, sbert_model):\n",
    "    def process_row(row):\n",
    "        claim, evidence = row[\"claim\"], row[\"evidence\"]\n",
    "        linguistic_features = extract_linguistic_features(spacy_model, claim, evidence)\n",
    "        semantic_features = extract_semantic_features(spacy_model, claim, evidence)\n",
    "        sbert_features = extract_sbert_features(sbert_model, claim, evidence)\n",
    "        return {**linguistic_features, **semantic_features, **sbert_features}\n",
    "\n",
    "    features_list = Parallel(n_jobs=-1)(\n",
    "        delayed(process_row)(row) for _, row in df.iterrows()\n",
    "    )\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "\n",
    "def extract_features(df):\n",
    "    features_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        claim = row[\"claim\"]\n",
    "        evidence = row[\"evidence\"]\n",
    "\n",
    "        # Extract features\n",
    "        linguistic_features = extract_linguistic_features(spacy_model, claim, evidence)\n",
    "        semantic_features = extract_semantic_features(spacy_model, claim, evidence)\n",
    "        sbert_features = extract_sbert_features(sbert_model, claim, evidence)\n",
    "\n",
    "        # Combine all features\n",
    "        combined_features = {\n",
    "            **linguistic_features,\n",
    "            **semantic_features,\n",
    "            **sbert_features,\n",
    "        }\n",
    "        combined_features[\"claim_id\"] = row[\"claim_id\"]\n",
    "        combined_features[\"doc_id\"] = row[\"doc_id\"]\n",
    "        combined_features[\"label\"] = row[\"label\"]\n",
    "        combined_features[\"is_evidence\"] = row[\"is_evidence\"]\n",
    "\n",
    "        features_list.append(combined_features)\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "\n",
    "train_features = extract_features(train_df)\n",
    "dev_features = extract_features(dev_df)\n",
    "\n",
    "train_features_p = extract_features_parallel(train_df, spacy_model, sbert_model)\n",
    "dev_features_p = extract_features_parallel(dev_df, spacy_model, sbert_model)\n",
    "\n",
    "display(train_features)\n",
    "diaplay(train_features_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40fd3a-65c6-4b8c-8624-5dd70bb19bcf",
   "metadata": {},
   "source": [
    "Reduce SBERT embeddings into features using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d170b-b998-4c34-a93a-a8ae494c295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_sbert_dimensions(features_df, n_components=50):\n",
    "    \"\"\"Reduce SBERT embedding dimensions using PCA.\"\"\"\n",
    "    # Combine claim and evidence embeddings\n",
    "    sbert_embeddings = np.hstack(\n",
    "        [\n",
    "            np.vstack(features_df[\"sbert_claim_embedding\"]),\n",
    "            np.vstack(features_df[\"sbert_evidence_embedding\"]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    reduced_embeddings = pca.fit_transform(sbert_embeddings)\n",
    "\n",
    "    # Create new feature columns\n",
    "    reduced_columns = [f\"sbert_pca_dim_{i}\" for i in range(n_components)]\n",
    "    reduced_df = pd.DataFrame(reduced_embeddings, columns=reduced_columns)\n",
    "\n",
    "    # Drop original embeddings and add reduced features\n",
    "    features_df = features_df.drop(\n",
    "        [\"sbert_claim_embedding\", \"sbert_evidence_embedding\"], axis=1\n",
    "    )\n",
    "    features_df = pd.concat([features_df, reduced_df], axis=1)\n",
    "\n",
    "    return features_df\n",
    "\n",
    "\n",
    "train_features = reduce_sbert_dimensions(train_features)\n",
    "dev_features = reduce_sbert_dimensions(dev_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be4f9a-5dd6-43ef-9ef0-9868d3e9f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Extracted {len(train_features.columns) - 4} features for training and development sets\"\n",
    ")\n",
    "print(f\"Training set shape: {train_features.shape}\")\n",
    "print(f\"Development set shape: {dev_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61211a1-787d-4b8c-bfef-7f77c1e4550d",
   "metadata": {},
   "source": [
    "Extract features for binary and relational classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf7312-7db0-4cb2-ac22-22b17de04635",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_X = train_features.drop(drop_features, axis=1)\n",
    "binary_train_y = train_features[\"is_evidence\"]\n",
    "\n",
    "binary_dev_X = dev_features.drop(drop_features, axis=1)\n",
    "binary_dev_y = dev_features[\"is_evidence\"]\n",
    "\n",
    "# Relation classification data (only for actual evidence)\n",
    "relation_train = train_features[train_features[\"is_evidence\"] == 1].copy()\n",
    "relation_train_X = relation_train.drop(drop_features, axis=1)\n",
    "relation_train_y = relation_train[\"label\"].map(label_encode)\n",
    "\n",
    "relation_dev = dev_features[dev_features[\"is_evidence\"] == 1].copy()\n",
    "relation_dev_X = relation_dev.drop(drop_features, axis=1)\n",
    "relation_dev_y = relation_dev[\"label\"].map(label_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c114dba-d191-47eb-b98b-098929d5e815",
   "metadata": {},
   "source": [
    "# Model Tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc38e5-6e56-48e7-9a1f-2a1633cdeb3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SCIBERT\n",
    "\n",
    "Train scibert on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c57da-f276-4ae2-83a6-6a953d201c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = ScifactDataset(train_df, tokenizer)\n",
    "dev_dataset = ScifactDataset(dev_df, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=8)\n",
    "\n",
    "trained_model = train_model(device, model, train_dataloader, dev_dataloader, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176df063-1b2c-4137-acbd-08a8c8efd392",
   "metadata": {},
   "source": [
    "### Binary Classifier\n",
    "\n",
    "Tune binary classifier hyper-parameter using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8494c88-d9c7-4b25-8b08-b6aa3a824200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def binary_objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    # Define the pipeline\n",
    "    binary_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=n_estimators,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=min_samples_split,\n",
    "                    min_samples_leaf=min_samples_leaf,\n",
    "                    max_features=max_features,\n",
    "                    random_state=42,\n",
    "                    class_weight=\"balanced\",\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Perform stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(\n",
    "        skf.split(binary_train_X, binary_train_y)\n",
    "    ):\n",
    "        binary_pipeline.fit(\n",
    "            binary_train_X.iloc[train_idx], binary_train_y.iloc[train_idx]\n",
    "        )\n",
    "        predictions = binary_pipeline.predict(binary_train_X.iloc[val_idx])\n",
    "\n",
    "        score = f1_score(binary_train_y.iloc[val_idx], predictions)\n",
    "        scores.append(score)\n",
    "\n",
    "        trial.report(score, step=fold_idx)\n",
    "        if trial.should_prune():\n",
    "            raise TrialPruned()\n",
    "\n",
    "    # Return the mean F1 score\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Run Optuna optimization\n",
    "binary_study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner())\n",
    "binary_study.optimize(binary_objective, n_trials=100, n_jobs=-1, show_progress_bar=True)\n",
    "best_binary_params = binary_study.best_params\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best hyperparameters for binary classifier:\", best_binary_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276bda9-00ae-45e4-b67e-fb23558a8c84",
   "metadata": {},
   "source": [
    "Create binary classifier pipeline with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36242596-7fcb-414a-af22-f4a8d57a7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the binary classifier with the best parameters\n",
    "binary_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=best_binary_params[\"n_estimators\"],\n",
    "                max_depth=best_binary_params[\"max_depth\"],\n",
    "                min_samples_split=best_binary_params[\"min_samples_split\"],\n",
    "                min_samples_leaf=best_binary_params[\"min_samples_leaf\"],\n",
    "                max_features=best_binary_params[\"max_features\"],\n",
    "                random_state=42,\n",
    "                class_weight=\"balanced\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the binary classifier with the best parameters\n",
    "binary_pipeline.fit(binary_train_X, binary_train_y)\n",
    "binary_predictions = binary_pipeline.predict(binary_dev_X)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "binary_accuracy = accuracy_score(binary_dev_y, binary_predictions)\n",
    "binary_f1 = f1_score(binary_dev_y, binary_predictions)\n",
    "\n",
    "print(f\"Binary Classification - Accuracy: {binary_accuracy:.4f}, F1: {binary_f1:.4f}\")\n",
    "print(\"\\nClassification Report (Binary):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        binary_dev_y, binary_predictions, target_names=[\"EVIDENCE\", \"NON-EVIDENCE\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2306d6f9-7abb-432d-baa1-f1e7d0ee7ee8",
   "metadata": {},
   "source": [
    "### Relation Classifier\n",
    "\n",
    "Tune relation classifier hyper-parameter using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac1c6c-5587-4f30-9eaa-b2f17fab3a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def relation_objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    C = trial.suggest_float(\"C\", 0.01, 100, log=True)\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n",
    "\n",
    "    # Define the pipeline\n",
    "    relation_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                SVC(\n",
    "                    C=C,\n",
    "                    kernel=kernel,\n",
    "                    gamma=gamma,\n",
    "                    probability=True,\n",
    "                    random_state=42,\n",
    "                    class_weight=\"balanced\",\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Perform stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(\n",
    "        skf.split(relation_train_X, relation_train_y)\n",
    "    ):\n",
    "        relation_pipeline.fit(\n",
    "            relation_train_X.iloc[train_idx], relation_train_y.iloc[train_idx]\n",
    "        )\n",
    "        predictions = relation_pipeline.predict(relation_train_X.iloc[val_idx])\n",
    "\n",
    "        score = f1_score(relation_train_y.iloc[val_idx], predictions)\n",
    "        scores.append(score)\n",
    "\n",
    "        trial.report(score, step=fold_idx)\n",
    "        if trial.should_prune():\n",
    "            raise TrialPruned()\n",
    "\n",
    "    # Return the mean F1 score\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Run Optuna optimization\n",
    "relation_study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner())\n",
    "relation_study.optimize(\n",
    "    relation_objective, n_trials=100, n_jobs=-1, show_progress_bar=True\n",
    ")\n",
    "best_relation_params = relation_study.best_params\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best hyperparameters for relation classifier:\", best_relation_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf6842-2afd-4122-95b3-7feb1442cba1",
   "metadata": {},
   "source": [
    "Create relation classifier pipeline with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b94a47-e0b5-4b74-89e7-1f34071e45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the relation classifier with the best parameters\n",
    "relation_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            SVC(\n",
    "                C=best_relation_params[\"C\"],\n",
    "                kernel=best_relation_params[\"kernel\"],\n",
    "                gamma=best_relation_params[\"gamma\"],\n",
    "                probability=True,\n",
    "                random_state=42,\n",
    "                class_weight=\"balanced\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the relation classifier with the best parameters\n",
    "relation_pipeline.fit(relation_train_X, relation_train_y)\n",
    "relation_predictions = relation_pipeline.predict(relation_dev_X)\n",
    "\n",
    "# Evaluate the relation classifier\n",
    "relation_accuracy = accuracy_score(relation_dev_y, relation_predictions)\n",
    "relation_f1 = f1_score(relation_dev_y, relation_predictions)\n",
    "\n",
    "print(\n",
    "    f\"Relation Classification - Accuracy: {relation_accuracy:.4f}, F1: {relation_f1:.4f}\"\n",
    ")\n",
    "print(\"\\nClassification Report (Relation):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        relation_dev_y, relation_predictions, target_names=[\"SUPPORT\", \"CONTRADICT\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08883c03-6f13-4fc1-89e1-d8ddb8ad98cd",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e181734-e903-4510-b873-0643d66ed2d4",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Prepare data for ensemble model meta classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d258a33-82fe-447a-bef0-db93352f961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "# meta_classifier = LogisticRegression()\n",
    "\n",
    "# Initialize ensemble\n",
    "ensemble = EnsembleModel(\n",
    "    device,\n",
    "    binary_pipeline,\n",
    "    relation_pipeline,\n",
    "    trained_model,\n",
    "    tokenizer,\n",
    "    meta_classifier,\n",
    ")\n",
    "\n",
    "# Prepare data for meta-classifier training\n",
    "print(\"Preparing data for meta-classifier training...\")\n",
    "\n",
    "# Get traditional model probabilities\n",
    "binary_train_probs = binary_pipeline.predict_proba(binary_train_X)\n",
    "\n",
    "# For relation classifier, align probabilities with the full training set\n",
    "relation_train_probs = np.zeros((len(train_df), 2))\n",
    "is_evidence_mask = train_features[\"is_evidence\"] == 1\n",
    "relation_train_probs[is_evidence_mask] = relation_pipeline.predict_proba(\n",
    "    relation_train_X\n",
    ")\n",
    "\n",
    "# Get transformer model probabilities\n",
    "train_claims = train_df[\"claim\"].tolist()\n",
    "train_evidences = train_df[\"evidence\"].tolist()\n",
    "bert_train_probs = ensemble.get_bert_predictions(train_claims, train_evidences)\n",
    "\n",
    "# Combine probabilities into a feature matrix\n",
    "meta_train_features = np.hstack(\n",
    "    [binary_train_probs, relation_train_probs, bert_train_probs]\n",
    ")\n",
    "meta_train_labels = train_df[\"label\"].map(label_encode).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ba8a9-bad9-4da4-b6ae-62af300f03ab",
   "metadata": {},
   "source": [
    "Train ensemble model meta classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdb35e-2df6-432f-b25d-b11f759f9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the meta-classifier\n",
    "print(\"Training the meta-classifier...\")\n",
    "ensemble.train_meta_classifier(meta_train_features, meta_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb999e0-237b-447b-8a64-bdf156698d1e",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Evaluate ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958c547-4b19-499f-823c-98abcfdada65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract required columns for prediction\n",
    "dev_claims = dev_df[\"claim\"].tolist()\n",
    "dev_evidences = dev_df[\"evidence\"].tolist()\n",
    "\n",
    "# Make predictions\n",
    "predictions = ensemble.predict(dev_features, dev_claims, dev_evidences)\n",
    "\n",
    "# Evaluate\n",
    "true_labels = dev_df[\"label\"].map(label_encode).values\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
    "\n",
    "print(\"\\nEnsemble Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        true_labels, predictions, target_names=[\"SUPPORT\", \"CONTRADICT\", \"NO_RELATION\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ee57b-29d5-41d7-a03b-63e643a95bcd",
   "metadata": {},
   "source": [
    "# Visiualizations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51829947-844d-4d82-b3c3-7978d256f7cf",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84b6d1-1164-4948-a553-6535e0a9c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions, labels=[0, 1, 2])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"SUPPORT\", \"CONTRADICT\", \"NO_RELATION\"],\n",
    "    yticklabels=[\"SUPPORT\", \"CONTRADICT\", \"NO_RELATION\"],\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for Ensemble Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20c33a-9e66-4de0-8a3f-55cd146ee13b",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a7ecf-97b3-487d-bcfc-cb25807f6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names and importances from the binary classifier\n",
    "binary_feature_names = binary_train_X.columns.tolist()\n",
    "binary_feature_importances = binary_pipeline.named_steps[\n",
    "    \"classifier\"\n",
    "].feature_importances_\n",
    "\n",
    "# Pair feature names with their importance scores\n",
    "features_with_importance = list(zip(binary_feature_names, binary_feature_importances))\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "sorted_features = sorted(features_with_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top 25 features\n",
    "top_n = 25\n",
    "top_features = sorted_features[:top_n]\n",
    "\n",
    "# Unpack feature names and importances for plotting\n",
    "top_feature_names, top_feature_importances = zip(*top_features)\n",
    "\n",
    "# Plot the top 25 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(top_feature_names, top_feature_importances, color=\"skyblue\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(f\"Top {top_n} Most Important Features (Binary Classifier)\")\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the most important feature at the top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c68d9-71fa-437e-9d9f-ad6b50390f0f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
